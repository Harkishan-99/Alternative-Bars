{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- By: Harkishan Singh Baniya\n",
    "- Email: harkishansinghbaniya@gmail.com\n",
    "- Reference : 1) Advances in Financial Machine Learning by Dr Marcos Lopez De Prado\n",
    "            2) https://mlfinlab.readthedocs.io/en/latest/labeling/tb_meta_labeling.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a part of article series **Alternative Bars on Alpaca**. In last two parts of the article, we have learnt about *Alternatives Bars* i.e. `tick bar`, `volume bar` and `dollar bar` and developed a trading strategy with 'volume bars' using Alpaca Trade API. <br>\n",
    "\n",
    "In this notebook, we will try to enhance the trading strategy by trying to reduce the amount of false-positive signals produced the strategy. This will be done using a technique called Meta-labelling *(AFML page-50 3.6)* by Dr Macros Lopez de Prado. In brief, meta-labelling is done by looking at the historical returns of a strategy or a model and label only the profitable trades (returns above a minimum threshold) as 1 and the rest 0. Then a model an ML model can train on the binary labels to decide whether to take a trade position or to avoid it.<br>\n",
    "\n",
    "The analysis will be performed on historical volume bars of SPY ETF trades data from *Jan 1st 2018* to *Dec 31st 2019* and will be using a dynamic sampling frequency/ thresholds as mentioned during the strategy development (refer article [part-ii](https://alpaca.markets/learn/alternative-bars-02/) ).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For generating the meta-labels, I will be using the [mlfinlab](https://mlfinlab.readthedocs.io/en/latest/index.html) Python package developed by [Hudson&Thames.org](https://hudsonthames.org/) and [pyfolio](https://www.quantopian.com/docs/user-guide/tools/pyfolio) by [Quantopian Inc.](https://www.quantopian.com/) for getting the performance metrics. User can easily install the packages using `pip install` or by running the below cell. Also, it uses [talib](https://mrjbq7.github.io/ta-lib/doc_index.html) technical analysis package to generate the Bollinger Bands. If itâ€™s not already installed it can be installed by `pip install talib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mlfinlab pyfolio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import talib as ta\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import pyfolio as pf\n",
    "from tqdm import tqdm\n",
    "import mlfinlab as ml\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the strategy parameter\n",
    "#lookback period for the Bollinger Bands\n",
    "lookback_period = 15\n",
    "#TP and SL\n",
    "tpsl = [10,5]\n",
    "#bars file\n",
    "file = '../sample_datasets/analysis/SPY_VBars.csv'\n",
    "#reading the bars\n",
    "bars = pd.read_csv(file, index_col=[0], parse_dates=True)\n",
    "#creating the Bollinger Bands \n",
    "bars['UB'], _, bars['LB'] = ta.BBANDS(bars.close, timeperiod=lookback_period, nbdevup=2, nbdevdn=2, matype=0)\n",
    "bars = bars.dropna()\n",
    "bars = bars.tz_localize('UTC').tz_convert('US/Eastern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>vwap</th>\n",
       "      <th>cum_volume</th>\n",
       "      <th>cum_ticks</th>\n",
       "      <th>cum_dollar_value</th>\n",
       "      <th>cum_buy_ticks</th>\n",
       "      <th>cum_sell_ticks</th>\n",
       "      <th>cum_buy_volume</th>\n",
       "      <th>cum_sell_volume</th>\n",
       "      <th>cum_buy_dollar_value</th>\n",
       "      <th>cum_sell_dollar_value</th>\n",
       "      <th>UB</th>\n",
       "      <th>LB</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02 10:28:28.226337024-05:00</th>\n",
       "      <td>268.30</td>\n",
       "      <td>268.38</td>\n",
       "      <td>268.2100</td>\n",
       "      <td>268.37</td>\n",
       "      <td>268.272298</td>\n",
       "      <td>877541.0</td>\n",
       "      <td>3979.0</td>\n",
       "      <td>2.354199e+08</td>\n",
       "      <td>527.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>128839.0</td>\n",
       "      <td>97547.0</td>\n",
       "      <td>3.456527e+07</td>\n",
       "      <td>2.616858e+07</td>\n",
       "      <td>268.448649</td>\n",
       "      <td>267.372684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 10:34:48.258940928-05:00</th>\n",
       "      <td>268.36</td>\n",
       "      <td>268.45</td>\n",
       "      <td>268.3200</td>\n",
       "      <td>268.37</td>\n",
       "      <td>268.371774</td>\n",
       "      <td>877577.0</td>\n",
       "      <td>4116.0</td>\n",
       "      <td>2.355169e+08</td>\n",
       "      <td>472.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>134167.0</td>\n",
       "      <td>104867.0</td>\n",
       "      <td>3.600725e+07</td>\n",
       "      <td>2.814287e+07</td>\n",
       "      <td>268.526686</td>\n",
       "      <td>267.382647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 10:38:25.482391040-05:00</th>\n",
       "      <td>268.37</td>\n",
       "      <td>268.45</td>\n",
       "      <td>267.9600</td>\n",
       "      <td>268.02</td>\n",
       "      <td>268.284520</td>\n",
       "      <td>877702.0</td>\n",
       "      <td>3439.0</td>\n",
       "      <td>2.354739e+08</td>\n",
       "      <td>454.0</td>\n",
       "      <td>484.0</td>\n",
       "      <td>111267.0</td>\n",
       "      <td>110587.0</td>\n",
       "      <td>2.985148e+07</td>\n",
       "      <td>2.966907e+07</td>\n",
       "      <td>268.525055</td>\n",
       "      <td>267.437612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 10:44:35.941316096-05:00</th>\n",
       "      <td>268.02</td>\n",
       "      <td>268.30</td>\n",
       "      <td>268.0135</td>\n",
       "      <td>268.23</td>\n",
       "      <td>268.177539</td>\n",
       "      <td>877886.0</td>\n",
       "      <td>4057.0</td>\n",
       "      <td>2.354293e+08</td>\n",
       "      <td>542.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>132313.0</td>\n",
       "      <td>104728.0</td>\n",
       "      <td>3.548200e+07</td>\n",
       "      <td>2.808525e+07</td>\n",
       "      <td>268.500557</td>\n",
       "      <td>267.570110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 10:51:50.436428032-05:00</th>\n",
       "      <td>268.23</td>\n",
       "      <td>268.30</td>\n",
       "      <td>268.2000</td>\n",
       "      <td>268.25</td>\n",
       "      <td>268.243706</td>\n",
       "      <td>877793.0</td>\n",
       "      <td>3551.0</td>\n",
       "      <td>2.354624e+08</td>\n",
       "      <td>380.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>93431.0</td>\n",
       "      <td>118681.0</td>\n",
       "      <td>2.506216e+07</td>\n",
       "      <td>3.183551e+07</td>\n",
       "      <td>268.519926</td>\n",
       "      <td>267.616074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       open    high       low   close  \\\n",
       "datetime                                                                \n",
       "2018-01-02 10:28:28.226337024-05:00  268.30  268.38  268.2100  268.37   \n",
       "2018-01-02 10:34:48.258940928-05:00  268.36  268.45  268.3200  268.37   \n",
       "2018-01-02 10:38:25.482391040-05:00  268.37  268.45  267.9600  268.02   \n",
       "2018-01-02 10:44:35.941316096-05:00  268.02  268.30  268.0135  268.23   \n",
       "2018-01-02 10:51:50.436428032-05:00  268.23  268.30  268.2000  268.25   \n",
       "\n",
       "                                           vwap  cum_volume  cum_ticks  \\\n",
       "datetime                                                                 \n",
       "2018-01-02 10:28:28.226337024-05:00  268.272298    877541.0     3979.0   \n",
       "2018-01-02 10:34:48.258940928-05:00  268.371774    877577.0     4116.0   \n",
       "2018-01-02 10:38:25.482391040-05:00  268.284520    877702.0     3439.0   \n",
       "2018-01-02 10:44:35.941316096-05:00  268.177539    877886.0     4057.0   \n",
       "2018-01-02 10:51:50.436428032-05:00  268.243706    877793.0     3551.0   \n",
       "\n",
       "                                     cum_dollar_value  cum_buy_ticks  \\\n",
       "datetime                                                               \n",
       "2018-01-02 10:28:28.226337024-05:00      2.354199e+08          527.0   \n",
       "2018-01-02 10:34:48.258940928-05:00      2.355169e+08          472.0   \n",
       "2018-01-02 10:38:25.482391040-05:00      2.354739e+08          454.0   \n",
       "2018-01-02 10:44:35.941316096-05:00      2.354293e+08          542.0   \n",
       "2018-01-02 10:51:50.436428032-05:00      2.354624e+08          380.0   \n",
       "\n",
       "                                     cum_sell_ticks  cum_buy_volume  \\\n",
       "datetime                                                              \n",
       "2018-01-02 10:28:28.226337024-05:00           503.0        128839.0   \n",
       "2018-01-02 10:34:48.258940928-05:00           461.0        134167.0   \n",
       "2018-01-02 10:38:25.482391040-05:00           484.0        111267.0   \n",
       "2018-01-02 10:44:35.941316096-05:00           516.0        132313.0   \n",
       "2018-01-02 10:51:50.436428032-05:00           360.0         93431.0   \n",
       "\n",
       "                                     cum_sell_volume  cum_buy_dollar_value  \\\n",
       "datetime                                                                     \n",
       "2018-01-02 10:28:28.226337024-05:00          97547.0          3.456527e+07   \n",
       "2018-01-02 10:34:48.258940928-05:00         104867.0          3.600725e+07   \n",
       "2018-01-02 10:38:25.482391040-05:00         110587.0          2.985148e+07   \n",
       "2018-01-02 10:44:35.941316096-05:00         104728.0          3.548200e+07   \n",
       "2018-01-02 10:51:50.436428032-05:00         118681.0          2.506216e+07   \n",
       "\n",
       "                                     cum_sell_dollar_value          UB  \\\n",
       "datetime                                                                 \n",
       "2018-01-02 10:28:28.226337024-05:00           2.616858e+07  268.448649   \n",
       "2018-01-02 10:34:48.258940928-05:00           2.814287e+07  268.526686   \n",
       "2018-01-02 10:38:25.482391040-05:00           2.966907e+07  268.525055   \n",
       "2018-01-02 10:44:35.941316096-05:00           2.808525e+07  268.500557   \n",
       "2018-01-02 10:51:50.436428032-05:00           3.183551e+07  268.519926   \n",
       "\n",
       "                                             LB  \n",
       "datetime                                         \n",
       "2018-01-02 10:28:28.226337024-05:00  267.372684  \n",
       "2018-01-02 10:34:48.258940928-05:00  267.382647  \n",
       "2018-01-02 10:38:25.482391040-05:00  267.437612  \n",
       "2018-01-02 10:44:35.941316096-05:00  267.570110  \n",
       "2018-01-02 10:51:50.436428032-05:00  267.616074  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sides(df):\n",
    "    \"\"\"\n",
    "    A function to get the trade sides either long\n",
    "    or short from up or down cross of the price\n",
    "    from the Bollinger Bands according to the \n",
    "    strategy.\n",
    "    \"\"\"\n",
    "    #up-cross\n",
    "    c1U = df.close.shift(1) < df.UB.shift(1)  \n",
    "    c2U = df.close > df.UB\n",
    "    #down-cross\n",
    "    c1D = df.close.shift(1) > df.LB.shift(1) \n",
    "    c2D = df.close < df.LB\n",
    "    #signals\n",
    "    sides = pd.Series(np.nan, index = df.index)\n",
    "    #LONG\n",
    "    sides.loc[(c1U) & (c2U)] = int(1)\n",
    "    #SHORT\n",
    "    sides.loc[(c1D) & (c2D)] = int(-1)\n",
    "    return sides.dropna()\n",
    "\n",
    "def get_hourly_volatility(close, lookback=10):\n",
    "    \"\"\"\n",
    "    Get the hourly volatility of a price series with\n",
    "    a given decay span.\n",
    "    \"\"\"\n",
    "    timedelta = pd.Timedelta('1 hours')\n",
    "    df0 = close.index.searchsorted(close.index - timedelta)\n",
    "    df0 = df0[df0 > 0]\n",
    "    df0 = (pd.Series(close.index[df0 - 1], index=close.index[close.shape[0] - df0.shape[0]:]))\n",
    "    df0 = close.loc[df0.index] / close.loc[df0.array].array - 1  # daily returns\n",
    "    df0 = df0.ewm(span=lookback).std()\n",
    "    return df0\n",
    "\n",
    "def get_vertical_barrier(close, sides):\n",
    "    \"\"\"\n",
    "    This function outputs the timestamps where the\n",
    "    position is closed due to a counter position that\n",
    "    had to be taken due to side flip while holding a\n",
    "    opposite position than the current one. \n",
    "    \n",
    "    This timestamp will be considered as the verticle\n",
    "    barrier or the point where we close the position \n",
    "    when neither the TP nor the SL hit has occured.\n",
    "    \"\"\"\n",
    "    #get the positions where side flips\n",
    "    t1 = pd.Series(pd.NaT, index=close.index)\n",
    "    prev_side = sides[0]\n",
    "    last_update = close.index[0]\n",
    "    for i in range(1, len(sides)):\n",
    "        if (sides[i] + prev_side) == 0:\n",
    "            #switch position i.e. close the current position and take a counter position\n",
    "            t1[last_update:sides.index[i]] = sides.index[i]\n",
    "            last_update = sides.index[i]\n",
    "        prev_side = sides[i]\n",
    "    t1 = t1.fillna(close.index[-1])\n",
    "    return t1\n",
    "\n",
    "def get_returns(bars, tpsl):\n",
    "    \"\"\"\n",
    "    A function to get the strategy returns from the \n",
    "    entry sides, volatility and the exit conditions \n",
    "    according to the strategy, the get_events function\n",
    "    from mlfinlab get the returns by applying these \n",
    "    parameters.\n",
    "    \n",
    "    :param bars :(pd.DataFrame) bars dataframe.\n",
    "    :param tpsl :(list) TP and SL for the strategy.\n",
    "                    \n",
    "    :return : (pd.DataFrame) a dataframe of the sides\n",
    "             generated by the strategy and the returns\n",
    "             for those.\n",
    "    \"\"\"\n",
    "    #signals i.e. LONG/SHORT (1/-1)\n",
    "    sides = get_sides(bars)\n",
    "    #hourly volatility\n",
    "    vol = get_hourly_volatility(bars.close)\n",
    "    #vertical barrier \n",
    "    t1 = get_vertical_barrier(bars.close, sides)\n",
    "    #get the 3B events \n",
    "    triple_barrier_events = ml.labeling.get_events(close=bars['close'],\n",
    "                                                   t_events=sides.index,\n",
    "                                                   pt_sl=tpsl,\n",
    "                                                   target=vol,\n",
    "                                                   min_ret=0.0,\n",
    "                                                   num_threads=4,\n",
    "                                                   vertical_barrier_times=t1,\n",
    "                                                   side_prediction=sides)\n",
    "    labels = ml.labeling.get_bins(triple_barrier_events, bars['close'])\n",
    "    return labels[['ret', 'side']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-16 15:42:37.411472 100.0% apply_pt_sl_on_t1 done after 0.16 minutes. Remaining 0.0 minutes.\n"
     ]
    }
   ],
   "source": [
    "#get the returns and sides for the bar sets\n",
    "ordinary_returns = get_returns(bars, tpsl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a copy of the bar set\n",
    "X = bars.copy()\n",
    "#adding the sides to the dataframe \n",
    "X['side'] = ordinary_returns['side']\n",
    "#adding log returns, volatility, momentum and RSI as features \n",
    "#more relevent features can be added here to improve the ML model\n",
    "X['returns'] = np.log(bars['close']).diff()\n",
    "X['volatility'] = bars['close'].rolling('H').std()\n",
    "X['momentum_5'] = bars['close'].pct_change(5)\n",
    "X['rsi_5'] = ta.RSI(bars['close'], 5)\n",
    "\n",
    "#formatting the returns and the dataframe to remove Nan values\n",
    "X['strat_returns'] = ordinary_returns.ret\n",
    "X = X.dropna()\n",
    "strat_ret = X['strat_returns']\n",
    "X = X.drop(['strat_returns', 'open', 'high', 'low', 'close', 'cum_ticks','cum_dollar_value'], 1)\n",
    "#converting the returns to binary labels\n",
    "y = np.sign(strat_ret)\n",
    "y[y <= 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vwap</th>\n",
       "      <th>cum_volume</th>\n",
       "      <th>cum_buy_ticks</th>\n",
       "      <th>cum_sell_ticks</th>\n",
       "      <th>cum_buy_volume</th>\n",
       "      <th>cum_sell_volume</th>\n",
       "      <th>cum_buy_dollar_value</th>\n",
       "      <th>cum_sell_dollar_value</th>\n",
       "      <th>UB</th>\n",
       "      <th>LB</th>\n",
       "      <th>side</th>\n",
       "      <th>returns</th>\n",
       "      <th>volatility</th>\n",
       "      <th>momentum_5</th>\n",
       "      <th>rsi_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02 15:23:02.304551936-05:00</th>\n",
       "      <td>268.394006</td>\n",
       "      <td>878054.0</td>\n",
       "      <td>451.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>140277.0</td>\n",
       "      <td>119020.0</td>\n",
       "      <td>3.764992e+07</td>\n",
       "      <td>3.194400e+07</td>\n",
       "      <td>268.394730</td>\n",
       "      <td>268.213937</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.043906</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>77.701663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 15:43:33.539259904-05:00</th>\n",
       "      <td>268.498840</td>\n",
       "      <td>877547.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>91038.0</td>\n",
       "      <td>80807.0</td>\n",
       "      <td>2.444393e+07</td>\n",
       "      <td>2.169628e+07</td>\n",
       "      <td>268.505270</td>\n",
       "      <td>268.202730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.078601</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>69.628955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 15:52:45.711525120-05:00</th>\n",
       "      <td>268.675839</td>\n",
       "      <td>880038.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>107477.0</td>\n",
       "      <td>143749.0</td>\n",
       "      <td>2.887657e+07</td>\n",
       "      <td>3.862005e+07</td>\n",
       "      <td>268.679802</td>\n",
       "      <td>268.172865</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.133800</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>84.656739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03 12:41:31.885147904-05:00</th>\n",
       "      <td>270.084926</td>\n",
       "      <td>961161.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>118977.0</td>\n",
       "      <td>141481.0</td>\n",
       "      <td>3.213508e+07</td>\n",
       "      <td>3.821330e+07</td>\n",
       "      <td>270.123896</td>\n",
       "      <td>269.740104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.101719</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>75.002486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03 15:40:10.644578048-05:00</th>\n",
       "      <td>270.499555</td>\n",
       "      <td>961156.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>132018.0</td>\n",
       "      <td>107326.0</td>\n",
       "      <td>3.571192e+07</td>\n",
       "      <td>2.903143e+07</td>\n",
       "      <td>270.522831</td>\n",
       "      <td>269.954369</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.111557</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>84.864758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           vwap  cum_volume  cum_buy_ticks  \\\n",
       "datetime                                                                     \n",
       "2018-01-02 15:23:02.304551936-05:00  268.394006    878054.0          451.0   \n",
       "2018-01-02 15:43:33.539259904-05:00  268.498840    877547.0          351.0   \n",
       "2018-01-02 15:52:45.711525120-05:00  268.675839    880038.0          433.0   \n",
       "2018-01-03 12:41:31.885147904-05:00  270.084926    961161.0          442.0   \n",
       "2018-01-03 15:40:10.644578048-05:00  270.499555    961156.0          354.0   \n",
       "\n",
       "                                     cum_sell_ticks  cum_buy_volume  \\\n",
       "datetime                                                              \n",
       "2018-01-02 15:23:02.304551936-05:00           446.0        140277.0   \n",
       "2018-01-02 15:43:33.539259904-05:00           352.0         91038.0   \n",
       "2018-01-02 15:52:45.711525120-05:00           415.0        107477.0   \n",
       "2018-01-03 12:41:31.885147904-05:00           428.0        118977.0   \n",
       "2018-01-03 15:40:10.644578048-05:00           342.0        132018.0   \n",
       "\n",
       "                                     cum_sell_volume  cum_buy_dollar_value  \\\n",
       "datetime                                                                     \n",
       "2018-01-02 15:23:02.304551936-05:00         119020.0          3.764992e+07   \n",
       "2018-01-02 15:43:33.539259904-05:00          80807.0          2.444393e+07   \n",
       "2018-01-02 15:52:45.711525120-05:00         143749.0          2.887657e+07   \n",
       "2018-01-03 12:41:31.885147904-05:00         141481.0          3.213508e+07   \n",
       "2018-01-03 15:40:10.644578048-05:00         107326.0          3.571192e+07   \n",
       "\n",
       "                                     cum_sell_dollar_value          UB  \\\n",
       "datetime                                                                 \n",
       "2018-01-02 15:23:02.304551936-05:00           3.194400e+07  268.394730   \n",
       "2018-01-02 15:43:33.539259904-05:00           2.169628e+07  268.505270   \n",
       "2018-01-02 15:52:45.711525120-05:00           3.862005e+07  268.679802   \n",
       "2018-01-03 12:41:31.885147904-05:00           3.821330e+07  270.123896   \n",
       "2018-01-03 15:40:10.644578048-05:00           2.903143e+07  270.522831   \n",
       "\n",
       "                                             LB  side   returns  volatility  \\\n",
       "datetime                                                                      \n",
       "2018-01-02 15:23:02.304551936-05:00  268.213937   1.0  0.000037    0.043906   \n",
       "2018-01-02 15:43:33.539259904-05:00  268.202730   1.0  0.000186    0.078601   \n",
       "2018-01-02 15:52:45.711525120-05:00  268.172865   1.0  0.000372    0.133800   \n",
       "2018-01-03 12:41:31.885147904-05:00  269.740104   1.0  0.000426    0.101719   \n",
       "2018-01-03 15:40:10.644578048-05:00  269.954369   1.0  0.000299    0.111557   \n",
       "\n",
       "                                     momentum_5      rsi_5  \n",
       "datetime                                                    \n",
       "2018-01-02 15:23:02.304551936-05:00    0.000298  77.701663  \n",
       "2018-01-02 15:43:33.539259904-05:00    0.000447  69.628955  \n",
       "2018-01-02 15:52:45.711525120-05:00    0.001342  84.656739  \n",
       "2018-01-03 12:41:31.885147904-05:00    0.001093  75.002486  \n",
       "2018-01-03 15:40:10.644578048-05:00    0.001110  84.864758  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meta model\n",
    "def train_model(X, y, split_date):\n",
    "    \"\"\"\n",
    "    A funtion to train a Random Forest as meta model \n",
    "    on the given features(X) and labels(y) and return \n",
    "    the prediction for out-of-sample (OOS) validation.\n",
    "    \"\"\"\n",
    "    X_train, y_train, X_val, y_val = X[:split_date], y[:split_date], X[split_date:], y[split_date:]\n",
    "    #defining a random forest model\n",
    "    model = RandomForestClassifier(n_estimators=800, max_depth=7, criterion='entropy', random_state=1, n_jobs=-1)\n",
    "    #fitting the model\n",
    "    model.fit(X_train, y_train)\n",
    "    # OOS prediction\n",
    "    y_pred = model.predict(X_val)\n",
    "    #displaying models preformance metrics out-of-sample (OOS)\n",
    "    print(f'(OOS) Accuracy : {accuracy_score(y_val, y_pred)}')\n",
    "    print(f'(OOS) Precision : {precision_score(y_val, y_pred)}')\n",
    "    print(f'(OOS) Recall : {recall_score(y_val, y_pred)}')\n",
    "    print(f'(OOS) Confusion Matrix : \\n {confusion_matrix(y_val, y_pred)}')\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(OOS) Accuracy : 0.5172413793103449\n",
      "(OOS) Precision : 0.4431818181818182\n",
      "(OOS) Recall : 0.8478260869565217\n",
      "(OOS) Confusion Matrix : \n",
      " [[21 49]\n",
      " [ 7 39]]\n"
     ]
    }
   ],
   "source": [
    "test_from_date = '2019-10-01'\n",
    "meta_signals = train_model(X, y, test_from_date)\n",
    "#get the normal return for the test period\n",
    "normal_rets = strat_ret[test_from_date:]\n",
    "#get the returns with the signals from meta-model for the test period\n",
    "rets_with_meta_model = strat_ret[test_from_date:] * meta_signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plain Strategy Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2019-10-01</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2019-12-30</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>5</td></tr>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backtest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Annual return</th>\n",
       "      <td>11.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumulative returns</th>\n",
       "      <td>5.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual volatility</th>\n",
       "      <td>9.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe ratio</th>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calmar ratio</th>\n",
       "      <td>1.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stability</th>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max drawdown</th>\n",
       "      <td>-6.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Omega ratio</th>\n",
       "      <td>1.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sortino ratio</th>\n",
       "      <td>2.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skew</th>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kurtosis</th>\n",
       "      <td>1.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tail ratio</th>\n",
       "      <td>1.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily value at risk</th>\n",
       "      <td>-1.1%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pf.show_perf_stats(normal_rets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy with Meta-model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2019-10-01</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2019-12-30</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>5</td></tr>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backtest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Annual return</th>\n",
       "      <td>27.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumulative returns</th>\n",
       "      <td>11.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual volatility</th>\n",
       "      <td>8.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe ratio</th>\n",
       "      <td>3.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calmar ratio</th>\n",
       "      <td>6.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stability</th>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max drawdown</th>\n",
       "      <td>-4.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Omega ratio</th>\n",
       "      <td>1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sortino ratio</th>\n",
       "      <td>6.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skew</th>\n",
       "      <td>1.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kurtosis</th>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tail ratio</th>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily value at risk</th>\n",
       "      <td>-0.9%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pf.show_perf_stats(rets_with_meta_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the above meta-model didn't perform much well in terms of accuracy and precision and there are a lot of reasons for that like tunning, feature selection etc. These topics don't fall under the scope of this article series but will be discussed later. The goal was to introduce the concept of meta-modelling and labelling to avoid some false positives as a filtering method. <br>\n",
    "As for the performance, we can see that the meta-model *outperforms* the plain strategy significantly with all the performance statistics like cumulative returns, Sharpe ratio, max drawdown, annual volatility etc.  The meta-model helped to reduce the max drawdown and increase the overall Sharpe ratio which was expected as the main motive was to filter out as many false positives as possible. Risk-averse investors can trade some of the recall from the model to increase the precision by keeping a threshold on the predicted probability (e.g. at 60%) from the meta-model. This way the investor can reduce their max drawdown and volatility further but will sacrifice some return in the process. <br>\n",
    "\n",
    "Improving the robustness of the model and the testing process can involve the following steps, but not limited to them only. \n",
    "- Use more relevant features for training.\n",
    "- Do features selection and engineering. \n",
    "- Tune the hyper-parameter of the model with cross-validation.\n",
    "- For the testing, I would recommend using an online learning setup for the model training and testing with moving window to keep the model relevant with the new information and not predicting long into the future when the model tends to decay in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
